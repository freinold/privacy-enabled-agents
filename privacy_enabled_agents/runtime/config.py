from typing import Literal, Self, TypedDict

from pydantic import BaseModel, Field, model_validator


class PrivacyAgentConfig(BaseModel):
    topic: Literal["basic", "websearch", "finance", "medical", "public-service"] = Field(
        default="basic",
        description="Topic of the privacy agent. Selects the resources, tools and prompts used.",
    )
    model_provider: Literal["openai", "mistral"] = Field(
        default="mistral",
        description="Model provider for the chat model. Currently only 'mistral' and 'openai' are supported.",
    )
    model_name: str = Field(
        default="mistral-medium-2508",
        description="Name of the chat model to use.",
    )
    model_temperature: float = Field(
        default=0.3,
        description="Temperature for the model.",
    )
    detector: Literal["gliner", "regex"] = Field(
        default="gliner",
        description="Detector type for the agent.",
    )
    replacer: Literal["placeholder", "encryption", "hash", "pseudonym"] = Field(
        default="placeholder",
        description="Replacer type for the agent.\n- Placeholder: Uses entity type based values like '[PERSON-01]'\n- Encryption: Only works with 'encryption' entity store, uses symmetric encryption.\n- Hash: Uses a hash function to obfuscate data.\n- Pseudonym: Replaces real names with pseudonyms generated by 'faker'.",
    )
    entity_store: Literal["valkey", "encryption"] = Field(
        default="valkey",
        description="Entity store type. 'encryption' only works with 'encryption' replacer.",
    )
    conversation_store: Literal["valkey"] = Field(
        default="valkey",
        description="Conversation store type. Currently only 'valkey' is supported.",
    )
    checkpointer: Literal["redis"] = Field(
        default="redis",
        description="Checkpointer type for the agent. Currently only 'redis' is supported.",
    )
    langfuse_enabled: bool = Field(
        default=True,
        description="Enable Langfuse for monitoring and prompt management. Set to False to disable.",
    )
    system_prompt: str | None = Field(
        default=None,
        description="Custom system prompt for the agent. If None, tries to first get the topic's default prompt from langfuse and then falls back to a built-in prompt.",
    )

    @model_validator(mode="after")
    def validate_encryption(self) -> Self:
        if (self.replacer == "encryption" or self.entity_store == "encryption") and not self.replacer == self.entity_store:
            raise ValueError("Replacer and entity store must both be 'encryption' if one is set to 'encryption'.")
        else:
            return self


class PrivacyAgentConfigDict(TypedDict, total=False):
    topic: str
    model_provider: str
    model_name: str
    model_temperature: float
    detector: str
    replacer: str
    entity_store: str
    conversation_store: str
    checkpointer: str
    langfuse_enabled: bool
    system_prompt: str | None
